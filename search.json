[{"url":"/2023/02/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Matplotib/","content":"中文显示from pylab import mplmpl.rcParams[&quot;font.sans-serif&quot;]=[&quot;SimHei&quot;]mpl.rcParams[&quot;axes.unicode_minu&quot;]= False\n添加网格显示plt.grid(True, linestyle=&quot;--&quot;,alpha=0.5)\n\n添加描述信息plt.xlable(&quot;时间&quot;)plt.ylable(&quot;温度&quot;)plt.title(&quot;中午的温度变化图&quot;，fontsize=20)\n图像保存plt.savefig(&quot;test.png&quot;)\n画图流程\nimport matplotlib.pyplot as pltimport randomfrom pylab import mpl# 设置显示中文字体from pylab import mplmpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]# 设置正常显示符号mpl.rcParams[&quot;axes.unicode_minus&quot;] = False# 0.准备数据x = range(60)y_shanghai = [random.uniform(15, 18) for i in x]# 1.创建画布plt.figure(figsize=(20, 8), dpi=100)# 2.绘制图像plt.plot(x, y_shanghai)# 2.1 添加x,y轴刻度# 构造x,y轴刻度标签x_ticks_label = [&quot;11点&#123;&#125;分&quot;.format(i) for i in x]y_ticks = range(40)# 刻度显示plt.xticks(x[::5], x_ticks_label[::5])plt.yticks(y_ticks[::5])# 2.2 添加网格显示plt.grid(True, linestyle=&quot;--&quot;, alpha=0.5)# 2.3 添加描述信息plt.xlabel(&quot;时间&quot;)plt.ylabel(&quot;温度&quot;)plt.title(&quot;中午11点--12点某城市温度变化图&quot;, fontsize=20)# 2.4 图像保存plt.savefig(&quot;./test.png&quot;)# 3.图像显示plt.show()\n\n一图多线多次plot\n# 增加北京的温度数据y_beijing = [random.uniform(1, 3) for i in x]# 绘制折线图plt.plot(x, y_shanghai)# 使用多次plot可以画多个折线plt.plot(x, y_beijing, color=&#x27;r&#x27;, linestyle=&#x27;--&#x27;)\n各图形及其语法折线图\napi: plt plot(x,y)\n散点图\napi: plt.scatter(x,y)\n\n柱状图\napi：plt.bar(x, width, align=&#x27;center&#x27;, **kwargs)Parameters:    x : 需要传递的数据width : 柱状图的宽度align : 每个柱状图的位置对齐方式    &#123;‘center’, ‘edge’&#125;, optional, default: ‘center’**kwargs :color:选择柱状图的颜色dadatwer\n直方图\napi: matplotilb.pyplot.hist(x,bins=None)Parameters:    x : 需要传递的数据bins : 组距\n饼图\napi: plt.pie(x,labels=,atuopct=,colors)Parameters:  x:数量，自动算百分比labels:每部分名称autopct:占比显示指定%1.2f%%colors:每部分颜色\n"},{"url":"/2023/02/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Numpy/","content":"生成数组a = np.array([[1,2,3],[4,5,6]])# 从现有的数组当中创建a1 = np.array(a)# 相当于索引的形式，并没有真正的创建一个新的a2 = np.asarray(a)\n 关于array和asarray的不同\n等于创建一个软链接当数组赋值给另外一个变量后，array：修改变量不会改变asarray： 会跟着改变\n\n\n生成各种不同的数组\n生成固定范围的数组np.linspace (start, stop, num, endpoint)参数:start:序列的起始值stop:序列的终止值num:要生成的等间隔样例数量，默认为50endpoint:序列中是否包含stop值，默认为ture等差数组np.arange(start,stop, step, dtype)参数step:步长,默认值为1np.arange(10, 50, 2)等比数组np.logspace(start,stop, num)num:要生成的等比数列数量，默认为50 生成随机数组np.random   \n\n正态分布创建方法\n准正态分布中返回一个或多个样本值np.random.randn(d0, d1, …, dn)np.random.normal(loc=0.0, scale=1.0, size=None)loc：float​ 此概率分布的均值（对应着整个分布的中心centre）scale：float​ 此概率分布的标准差（对应于分布的宽度，scale越大越矮胖，scale越小，越瘦高）size：int or tuple of ints​ 输出的shape，默认为None，只输出一个值返回指定形状的标准正态分布的数组。np.random.standard_normal(size=None)\n\n均匀分布np.random.rand(d0, d1, ..., dn)返回一组均匀分布的数。从一个均匀分布[low,high)中随机采样，注意定义域是左闭右开，即包含low，不包含high.np.random.uniform(low=0.0, high=1.0, size=None均匀分布中随机采样，生成一个整数或N维整数数组np.random.randint(low, high=None, size=None, dtype=&quot;l&quot;)取数范围：若high不为None时，取[low,high)之间随机整数，否则取值[0,low)之间随机整数。\n\n形状修改返回一个具有相同数据域，但shape不一样的视图行、列不进行互换ndarray.reshape(shape, order)修改数组本身的形状（需要保持元素个数前后相同）行、列不进行互换ndaarray.resize(new_shape)数组的转置将数组的行、列进行互换ndaarray.T\n\n类型修改返回修改了类型之后的数组stock_change.astype(np.int32)构造包含数组中原始数据字节的Python字节  arr = np.array([[[1, 2, 3], [4, 5, 6]], [[12, 3, 34], [5, 6, 7]]])arr.tostring()\n返回给定的形状哥类型的新数组，用0填充numpy.zeros(shape，dtype&#x3D;float，order &#x3D; ‘C’)\n返回给定形状和类型的新数组，用0填充。参数：\tshape：int 或 int 的元组 \t新阵列的形状，例如：（2，3）或2。 \tdtype：数据类型，可选 \t数组的所需数据类型，例如numpy.int8。默认是numpy.float64 \torder：&#123;&#x27;C&#x27;，&#x27;F&#x27;&#125;，可选，默认：&#x27;C&#x27; \t是否在内容中以行（C）或列（F）顺序存储多维数据。返回：\tout：ndarray \t具有给定形状，类型和顺序的0的数组。np.zeros((2,3))Out[2]: array([[ 0.,  0.,  0.],       [ 0.,  0.,  0.]])\n\n\n分组频数计算\nmean() 取平均值nunique方法计算pandas Series的唯一值计算（去重）value_counts方法获取pandas Series的频数统计\n\nto_numeric 函数变量转换为数值类型（int，float）\nDataFrame每一列的数据类型必须相同，当有些数据中有缺失，但不是NaN时（如missing,null等），会使整列数据变成字符串类型而不是数值型，这个时候可以使用to_numeric处理pd.to_numeric(tips_sub_miss[&#x27;total_bill&#x27;])to_numeric函数有一个参数errors,它决定了当该函数遇到无法转换的数值时该如何处理默认情况下,该值为raise,如果to_numeric遇到无法转换的值时,会抛错coerce: 如果to_numeric遇到无法转换的值时,会返回NaNignore: 如果to_numeric遇到无法转换的值时会放弃转换,什么都不做pd.to_numeric(tips_sub_miss[&#x27;total_bill&#x27;],errors = &#x27;ignore&#x27;)to_numeric向下转型to_numeric函数还有一个downcast参数, downcast接受的参数为 &#x27;integer&#x27;,&#x27;signed&#x27;,&#x27;float&#x27;,&#x27;unsigned&#x27;downcast参数设置为float之后, total_bill的数据类型由float64变为float32pd.to_numeric(tips_sub_miss[&#x27;total_bill&#x27;],errors = &#x27;coerce&#x27;,downcast=&#x27;float&#x27;)\n\n分类数据(category)Pandas 有一种类别数据, category,用于对分类值进行编码\n转换为category类型tips[&#x27;sex&#x27;] = tips[&#x27;sex&#x27;].astype(&#x27;str&#x27;) tips.info()\nPandas 数据类型转换Pandas除了数值型的int 和 float类型外，还有object ，category，bool，datetime类型可以通过as_type 和 to_numeric 函数进行数据类型转换Pandas 分类数据类型category类型，可以用来进行排序，并且可以自定义排序顺序CategoricalDtype可以用来定义顺序\n"},{"url":"/2023/02/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ndarray%E8%BF%90%E7%AE%97/","content":"逻辑运算# 随机生成10名同学，5门功课的数据score = np.random.randint(40, 100,(10,5))print(score)# 切片 取出最后4名同学的成绩，用逻辑判断test_score = score[6:, 0:5]# 逻辑判断print(test_score &gt; 60)# 布尔索引(满足条件替换)print(test_score[test_score &gt; 60] =1)判断or&amp;and# 判断前两名同学的成绩[0:2, :]是否全及格&gt;&gt;&gt; np.all(score[0:2, :] &gt; 60)Falsenp.any()# 判断前两名同学的成绩[0:2, :]是否有大于90分的&gt;&gt;&gt; np.any(score[0:2, :] &gt; 80)True\n\n三目运算# 判断前四名学生,前四门课程中，成绩中大于60的置为1，否则为0temp = score[:4, :4]np.where(temp &gt; 60, 1, 0)# 判断前四名学生,前四门课程中，成绩中大于60且小于90的换为1，否则为0np.where(np.logical_and(temp &gt; 60, temp &lt; 90), 1, 0)# 判断前四名学生,前四门课程中，成绩中大于90或小于60的换为1，否则为0np.where(np.logical_or(temp &gt; 90, temp &lt; 60), 1, 0)\n\n数组运算时的广播机制：\n数组在进行矢量化运算时，要求数组的形状是相等的。"},{"url":"/2023/02/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/kaikeba/","content":"mean(平均值)热数据\nsns.heatmap(dataframe.corr(), annot=True, fmt=&#x27;.1f&#x27;)\n(例子用于理解)对比两个最小值的均值（第一个age 提取出年龄）（[:2]（把排好序的的两个拿出））\nnp.mean([age for name ,age in sorted(person_and_age.items(), key = lambda e: e[1])[:2]])\n对比两个最小值的均值【:topn】(最前的两个数值)history_price(数据)e[0](取 面积：价格 的面积)\ndef find_price_by_similar(history_price,query_x, topn=3):\tmost_similar_items = sorted(history_price.items(), key= lambda e: (e[0] - query_x)**2)[:topn]\tmost_similar_prices = [price for rm, price in most_similar_items]\taverage_prices = np.mean(most_similar_prices)\treturn average_prices\n\n回归预测结果产生的是一个数值，分类产生一个类别KNN&#x3D;&#x3D;&gt;K-Neighbor-Nearest\n拟合效果 是获取最优的k，b的问题\n损失函数：Loss越接近0，越准确\n𝑓(𝑟𝑚)=𝑘∗𝑟𝑚+𝑏Random Approach𝐿𝑜𝑠𝑠(𝑘,𝑏)=1𝑛∑𝑖∈𝑁(𝑦𝑖^−𝑦𝑖)2 𝐿𝑜𝑠𝑠(𝑘,𝑏)=1𝑛∑𝑖∈𝑁((𝑘∗𝑟𝑚𝑖+𝑏)−𝑦𝑖)2\n怎么获取最优的k&amp;b？1.直接用微积分的方法做计算（最小二乘法）（简单才用，基本不用）2.用随机模拟的方法来做（随机生成一堆数）也叫：蒙特卡洛模拟\ndef loss(y_hat, y):    return np.mean((y_hat - y) ** 2)import randommin_loss = float(&#x27;inf&#x27;)best_k, bes_b = None, Nonefor step in range(1000):    min_v, max_v = -100, 100    k, b = random.randrange(min_v, max_v), random.randrange(min_v, max_v)    y_hats = [k * rm_i  + b for rm_i in x]    current_loss = loss(y_hats, y)        if current_loss &lt; min_loss:        min_loss = current_loss        best_k, best_b = k, b        print(&#x27;在第&#123;&#125;步，我们获得了函数 f(rm) = &#123;&#125; * rm + &#123;&#125;, 此时loss是: &#123;&#125;&#x27;.format(step, k, b, current_loss))\n蒙特卡洛模拟Supervisor𝐿𝑜𝑠𝑠(𝑘,𝑏)=1/𝑛*∑𝑖∈𝑁((𝑘∗𝑟𝑚𝑖+𝑏)−𝑦𝑖)2∂𝑙𝑜𝑠𝑠(𝑘,𝑏)/∂𝑘=2/𝑛*∑𝑖∈𝑁(𝑘∗𝑟𝑚𝑖+𝑏−𝑦𝑖)∗𝑟𝑚𝑖∂𝑙𝑜𝑠𝑠(𝑘,𝑏)/∂𝑏=2/𝑛*∑𝑖∈𝑁(𝑘∗𝑟𝑚𝑖+𝑏−𝑦𝑖)\ndef partial_k(k, b, x, y):    return 2 * np.mean((k * x + b - y) * x)def partial_b(k, b, x, y):    return 2 * np.mean(k * x + b - y)k_history, b_history = [], []loss_history = []k, b = random.random(), random.random()min_loss = float(&#x27;inf&#x27;)best_k, bes_b = None, Nonelearning_rate = 1e-2for step in range(2000):    k, b = k + (-1 * partial_k(k, b, x, y) * learning_rate), b + (-1 * partial_b(k, b, x, y) * learning_rate)    y_hats = k * x + b    current_loss = loss(y_hats, y)        if current_loss &lt; min_loss:        min_loss = current_loss        best_k, best_b = k, b        k_history.append(best_k)        b_history.append(best_b)        loss_history.append(current_loss)        print(&#x27;在第&#123;&#125;步，我们获得了函数 f(rm) = &#123;&#125; * rm + &#123;&#125;, 此时loss是: &#123;&#125;&#x27;.format(step, k, b, current_loss))\n\n深度学习的核心 ： 通过梯度下降的方法，获得一组参数，是的loss最小loss偏导式 + 梯度下降\n将课堂代码中的L2-Loss 变成L1Loss 并且实现梯度下降\n𝐿2−𝐿𝑜𝑠𝑠(𝑦,𝑦̂ )=1/𝑛*∑(𝑦̂ −𝑦)2 𝐿1−𝐿𝑜𝑠𝑠(𝑦,𝑦̂ )=1/𝑛*∑|(𝑦̂ −𝑦)|\n"},{"url":"/2023/02/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pandas/","content":"创建Series\nimport pandas as pd s = pd.Series([&#x27;banana&#x27;,42])\n创建DataFrame\nname_list = pd.DataFrame(\t&#123;\t\t&#x27;Name&#x27;:[&#x27;Tome&#x27;,&#x27;Bob&#x27;], \t\t&#x27;Occupation&#x27;:[&#x27;Teacher&#x27;,&#x27;IT Engineer&#x27;], \t\t&#x27;age&#x27;:[28,36]\t&#125;)\nSeries 常用操作loc\t使用索引值取子集iloc \t使用索引位置取子集dtype或dtypes Series\t内容的类型T \tSeries的转置矩阵shape \t数据的维数size \tSeries中元素的数量values \tSeries的值.value_counts()\t\t统计value数量director.count() \t返回非空值describe() \t打印描述信息\nSeries的一些方法方法 \t说明append \t连接两个或多个Seriescorr \t计算与另一个Series的相关系数cov\t 计算与另一个Series的协方差describe 计算常见统计量drop_duplicates \t返回去重之后的Seriesequals \t\t判断两个Series是否相同get_values \t获取Series的值，作用与values属性相同hist \t绘制直方图isin Series\t中是否包含某些值min \t返回最小值max\t返回最大值mean\t返回算术平均值median\t返回中位数mode \t返回众数quantile \t返回指定位置的分位数replace \t用指定值代替Series中的值sample\t 返回Series的随机采样值sort_values \t对值进行排序to_frame\t把Series转换为DataFrameunique \t\t去重返回数组\n两个Series之间计算，如果Series元素个数相同，则将两个Series对应元素进行计算；元素不同则缺失用NaN表示\nDataFramendim 查看数集的维度set_index 修改索引drop 删除列to_pickle 保存read_pickle 读取to_csv  保存成csv文件格式：(&#x27;output/scientists_df.tsv&#x27;,sep=&#x27;\\t&#x27;)to_clipboard 把数据保存到系统剪贴板，方便粘贴to_dict 把数据转换成Python字典to_hdf 把数据保存为HDF格式to_html 把数据转换成HTMLto_json 把数据转换成JSON字符串to_sql 把数据保存到SQL数据库nlargest(100,&#x27;imdb_score&#x27;)0.1统计数值列，并进行转置college.describe().T统计多方式数值.describe()nlargest方法显示出某列的排序nlargest(100,&#x27;imdb_score&#x27;).head()传入一个字典agg(&#x27;key&#x27;:&#x27;value&#x27;)\n聚合重点agg\n数据链接concat\t把dataframe(简单叠堆)ignore_index = True\t忽略后面DataFrame的索引添加列（默认添加行），传入参数 axis = columnscol_concat = pd.concat([df1,df2,df3],axis=1)向DataFrame添加一列，不需要调用函数，通过dataframe[&#x27;列名&#x27;] = [&#x27;值&#x27;] 即可\n链接数据库pd.read_sql_table从数据库中读取表，第一个参数是表名，第二个参数是数据库连接对象\nhow = ’left‘ 对应SQL中的 left outer 保留左侧表中的所有keyhow = ’right‘ 对应SQL中的 right outer 保留右侧表中的所有keyhow = &#x27;outer&#x27; 对应SQL中的 full outer 保留左右两侧侧表中的所有keyhow = &#x27;inner&#x27; 对应SQL中的 inner 只保留左右两侧都有的key转换：to_timedelta 将Milliseconds列转变为timedelta数据类型dt.floor(&#x27;s&#x27;) dt.floor() 时间类型数据，按指定单位截断数据DataFrame的assign方法：创建新列.assignjoin合并，依据两个DataFrame的行索引，如果合并的两个数据有相同的列名，需要通过lsuffix，和rsuffix，指定合并后的列名的前缀stocks_2016.join(stocks_2017, lsuffix=&#x27;_2016&#x27;, rsuffix=&#x27;_2017&#x27;, how=&#x27;outer&#x27;)concat, join, 和merge的区别concat ：Pandas函数可以垂直和水平地连接两个或多个pandas对象只用索引对齐默认是外连接（也可以设为内连接）join ：DataFrame方法只能水平连接两个或多个pandas对象对齐是靠被调用的DataFrame的列索引或行索引和另一个对象的行索引（不能是列索引）通过笛卡尔积处理重复的索引值默认是左连接（也可以设为内连接、外连接和右连接）merge ：DataFrame方法只能水平连接两个DataFrame对象对齐是靠被调用的DataFrame的列或行索引和另一个DataFrame的列或行索引通过笛卡尔积处理重复的索引值默认是内连接（也可以设为左连接、外连接、右连接）\n\n缺失数据处理keep_default_na = False 关闭NaN显示ffill 填充，用时间序列中空值的上一个非空值填充city_day.fillna(method=&#x27;ffill&#x27;,inplace=True) city_day[&#x27;Xylene&#x27;][50:65]用时间序列中空值的下一个非空值填充method=&#x27;bfill&#x27;线性差值方法limit_direction=&quot;both&quot;\n整理数据melt既可以用pd.melt, 也可使用dataframe.melt()\nframe dataframe 被 melt 的数据集名称在 pd.melt() 中使用id_vars tuple/list/ndarray \t可选项不需要被转换的列名，在转换后作为标识符列（不是索引列）value_vars tuple/list/ndarray \t可选项需要被转换的现有列如果未指明，除 id_vars 之外的其他列都被转换var_name string variable \t默认值自定义列名名称设置由 &#x27;value_vars&#x27; 组成的新的 column namevalue_name string value \t默认值自定义列名名称设置由 &#x27;value_vars&#x27; 的数据组成的新的 column namecol_level int/string \t可选项如果列是MultiIndex，则使用此级别数据整理（函数自动处理）pew_long = pd.melt(pew,id_vars=&#x27;religion&#x27;)pew_long\n处理查询冗余对于同一首歌曲来说，歌曲信息是完全一样的，可以考虑单独保存歌曲信息减少上表中保存的歌曲信息，可以节省存储空间，需要完整信息的时候，可以通过merge拼接数据我们可以把year,artist,track,time和date.entered放入一个新的dataframe中1.提取表信息，进行去重illboard_songs = bill_borad_long[[&#x27;year&#x27;,&#x27;artist&#x27;,&#x27;track&#x27;,&#x27;time&#x27;,&#x27;date.entered&#x27;]] billboard_songs = billboard_songs.drop_duplicates()billboard_songs2.为新拆分处理出来的数据添加ID列（添加ID）billboard_songs[&#x27;id&#x27;] = range(len(billboard_songs)) billboard_songs3.数据拆分成两个dataframe：billboard_songs和 billboard_ratings取出每周评分，去掉冗余部分billboard_ratings = bill_borad_long.merge(billboard_songs,on=[&#x27;year&#x27;,&#x27;artist&#x27;,&#x27;track&#x27;,&#x27;time&#x27;,&#x27;date.entered&#x27;]) billboard_ratings = billboard_ratings[[&#x27;id&#x27;,&#x27;week&#x27;,&#x27;rating&#x27;]] billboard_ratings4.用merage还原数据billboard_songs.merge(billboard_ratings,on=[&#x27;id&#x27;])\nstack整理数据用rename_axis给不同的行索引层级命名reset_index()，将结果变为DataFrame\nwide_to_long整理数据stubs = [&#x27;actor&#x27;, &#x27;actor_facebook_likes&#x27;]actor2_tidy = pd.wide_to_long(actor2, stubnames=stubs, i=[&#x27;movie_title&#x27;], j=&#x27;actor_num&#x27;, sep=&#x27;_&#x27;).reset_index() actor2_tidy.head()\nunstack 处理数据之前介绍了stack，unstack可以将stack的结果恢复\nstate_fruit.stack().unstack()\n\n\n自定义方法.apply(方法名)\n向量函数def avg_2_mod(x,y): \tif(x==20): \t\treturn (np.NaN) \telse:return (x+y)/2 avg_2_mod(df[&#x27;a&#x27;],df[&#x27;b&#x27;])上面函数中, x==20 , x 是向量, 但20是标量, 不能直接计算. 这个时候可以使用np.vectorize将函数向量化使用装饰器@np.vectorize def vec_avg_2_mod(x,y): \tif(x==20):\t\t return (np.NaN) \telse:\t\treturn (x+y)/2 vec_avg_2_mod(df[&#x27;a&#x27;],df[&#x27;b&#x27;])\nlambda函数df.apply(lambda x: x+1)\nPandas内置的聚合方法Pandas\t方法 Numpy函数 说明count \tnp.count_nonzero \t频率统计(不包含NaN值)size \t频率统计(包含NaN值)mean np.mean \t求平均值std np.std \t标准差min np.min \t最小值quantile() \tnp.percentile() \t分位数max np.max \t求最大值sum np.sum \t求和var np.var \t方差describe \t计数、平均值、标准差，最小值、分位数、最大值first \t返回第一行last \t返回最后一行nth 返回第N行(Python从0开始计数)\naggagg.(‘列名’:’方法名’).rename(‘原名’：’新名’)\n转换transform 转换，需要把DataFrame中的值传递给一个函数， 而后由该函数”转换”数据。aggregate(聚合) 返回单个聚合值，但transform 不会减少数据量\n# 计算z-score x - 平均值/标准差 def my_zscore(x): \treturn (x-x.mean())/x.std() #按年分组 计算z-score df.groupby(&#x27;year&#x27;).lifeExp.transform(my_zscore)\ntransform分组填充缺失值之前介绍了填充缺失值的各种方法，对于某些数据集，可以使用列的平均值来填充缺失值。某些情况下，可以考虑将列进行分组，分组之后取平均再填充缺失值tips_10 = pd.read_csv(&#x27;data/tips.csv&#x27;).sample(10,random_state = 42) tips_10"},{"url":"/2023/02/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/","content":"算法分为：\n监督学习\n\n\n定义：输入数据是由输入特征值和目标值所组成\n函数的输出可以是连续的值（回归）\n或是输出有限个离散值（分类）\n\n\n\n\n无监督学习\n\n\n定义：输入数据是由输入特征值组成，没有目标值\n输入数据没有被标记，也没有确定的结果。样本数据类别未知\n需要根据样本间的相似性对样本集进行类别划分\n\n\n\n\n半监督学习\n\n\n定义训练集同时包含有标记样本数据和未标记样本数据\n\n\n强化学习\tIn\tOut\t目的\t案例监督学习(supervised learning)\t有标签\t有反馈\t 预测结果\t猫狗分类 房价预测无监督学习(unsupervised learning)\t无标签\t无反馈\t   发现潜在结构\t“物以类聚，人以群分”半监督学习(Semi-Supervised Learning) 部分  有标签，     部分无标签\t有反馈\t降低数据标记的难度\t强化学习(reinforcement learning) 决策流程及激励系统 一系列行动\t长期利益最大化\t学下棋\n\n工作流1.获取数据2.数据基本处理- 1.缩小数据集范围DataFrame.query()- 2.选取有用的时间特征- 3.将签到位置少于n个用户的删除3.特征工程- 特征提取- 特征预处理- 特征降维- 特征预处理(标准化)4.机器学习(模型训练)5.模型评估- 结果达到要求，上线服务- 没有达到要求，重新上面步骤\n"},{"url":"/2023/02/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/","content":"(M行, N列)*(N行, L列) &#x3D; (M行, L列)C &#x3D; A x B\nc(1,1) &#x3D; （1行1 * 1列1）+ （1行2 *1列2）…c(1,2) &#x3D; （1行1 * 2列1）+ （1行2 *2列2）…矩阵乘法的性质矩阵的乘法不满足交换律：A×B≠B×A\n矩阵的乘法满足结合律。即：A×（B×C）&#x3D;（A×B）×C\n单位矩阵：在矩阵的乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的 1,我们称 这种矩阵为单位矩阵．它是个方阵，一般用 I 或者 E 表示，从 左上角到右下角的对角线（称为主对角线）上的元素均为 1 以外全都为 0\n矩阵乘法api：np.matmulnp.dot\nnp.matmul和np.dot的区别:二者都是矩阵乘法。 np.matmul中禁止矩阵与标量的乘法。 在矢量乘矢量的內积运算中，np.matmul与np.dot没有区别。\n"}]